#pragma once

#include <vector>
#include <Eigen/Core>
#include <Eigen/Cholesky>
#include "Kernel"

template <typename KernelType = RBFKernel>
class GaussianProcess
{
 public:
  GaussianProcess(const KernelType& kernel, double noise) : kernel(kernel), noise(noise) {}

  void addObservation(const Eigen::VectorXd& x, double y)
  {
    inputs.push_back(x);
    outputs.push_back(y);
  }

  // 找到最佳的解
  std::pair<Eigen::VectorXd, double> minimum() const
  {
    Eigen::VectorXd x =
        inputs[std::distance(outputs.begin(), std::min_element(outputs.begin(), outputs.end()))];
    double y = *std::min_element(outputs.begin(), outputs.end());
    return std::make_pair(x, y);
  }

  std::pair<double, double> predict(const Eigen::VectorXd& xNew) const
  {
    if (inputs.empty()) return {0.0, 1.0};
    int n = inputs.size();

    Eigen::VectorXd k(n);
    for (int i = 0; i < n; i++) k[i] = this->kernel(xNew, inputs[i]);

    Eigen::VectorXd kTransKInv = KInv * k;
    double mean = kTransKInv.dot(Eigen::Map<const Eigen::VectorXd>(outputs.data(), n));
    double variance = this->kernel(xNew, xNew) - k.dot(kTransKInv);
    return {mean, std::max(0.0, variance)};
  }

  void update()
  {
    int n = inputs.size();
    Eigen::MatrixXd K(n, n);
    for (int i = 0; i < n; i++)
    {
      for (int j = 0; j < n; j++)
      {
        K(i, j) = this->kernel(inputs[i], inputs[j]);
      }
    }

    K += noise * Eigen::MatrixXd::Identity(n, n);
    KInv = K.llt().solve(Eigen::MatrixXd::Identity(n, n));
  }

 private:
  double noise;
  std::vector<Eigen::VectorXd> inputs;
  std::vector<double> outputs;
  KernelType kernel;
  Eigen::MatrixXd KInv;
};
